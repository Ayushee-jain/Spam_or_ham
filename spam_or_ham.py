# -*- coding: utf-8 -*-
"""SMS Spam Collection Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IP1iJP3LaRYozITRuj2uiOmFA2vw2wzL
"""

!unzip '/content/sms_spam_collection_dataset.zip'

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

data=pd.read_csv('/content/spam.csv',encoding='ISO-8859-1')

data.head()

data.shape

data.isnull().sum()

data=data.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'])

data.head()

data=data.rename(columns={'v1':'label','v2':'text'})

data.head()

data['label'].value_counts()

ham=data[data['label']=='ham']

ham.head()

spam=data[data['label']=='spam']

spam.head()

ham.shape,spam.shape

ham=ham.sample(spam.shape[0])

ham.shape

df=ham.append(spam,ignore_index=True)
df=df.reset_index()
df.head()

df=df.drop(columns=['index'])

a=[]
for i in range(0,len(df)):
  a.append(len(df['text'][i]))

df['length']=a

import string
count = lambda l1,l2: sum([1 for x in l1 if x in l2])
b=[]
for i in range(0,len(df)):
  b.append(count(df['text'][i],set(string.punctuation)))

df['punctutaion']=b

df.tail()

plt.hist(df[df['label']=='ham']['length'],bins=100,alpha=0.7)
plt.hist(df[df['label']=='spam']['length'],bins=100,alpha=0.7)
plt.show()

plt.hist(df[df['label']=='ham']['punctutaion'],bins=100,alpha=0.7)
plt.hist(df[df['label']=='spam']['punctutaion'],bins=100,alpha=0.7)
plt.show()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(df['text'],df['label'],test_size=0.2,random_state=0,shuffle=True,stratify=df['label'])

from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
clf=Pipeline([('tfidf',TfidfVectorizer()),('clf',RandomForestClassifier(n_estimators=100,n_jobs=-1))])

clf.fit(x_train,y_train)

y_pred=clf.predict(x_test)

from sklearn.metrics import accuracy_score,confusion_matrix
confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
clf=Pipeline([('tfidf',TfidfVectorizer()),('clf',SVC(C=1000,gamma='auto'))])

clf.fit(x_train,y_train)

y_pred=clf.predict(x_test)

from sklearn.metrics import accuracy_score,confusion_matrix
confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

